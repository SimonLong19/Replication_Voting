{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Yiteng Long (Simon)'s Replication: \n",
    "SMM estimation in DellaVigna, List, Malmendier and Rao, 2017, \"Voting To Tell Others\""
   ],
   "id": "cd65a42602a21882"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 86,
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "from scipy.linalg import block_diag\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "# Import the empirical moments \n",
    "# I add baseline turnnout rate and flatten the imported data\n",
    "dt_empmoments = loadmat('d:/Users/29457/Desktop/26Fall/Coding Sample/Moments.mat')                         \n",
    "emp_moments = [dt_empmoments[\"Moments\"]]\n",
    "emp_moments = [item for sublist in emp_moments for item in sublist]       \n",
    "emp_moments.append(np.array([0.6000]))                                    \n",
    "emp_moments = np.ndarray.flatten(np.array(emp_moments))        \n",
    "\n",
    "# Import empirical var-cov matrix; 101 moments\n",
    "# W is the inverse, used as weighting matrix in SMM\n",
    "emp_moments_varcov =  dt_empmoments[\"VCcontrol\"]                          \n",
    "emp_moments_varcov = block_diag(emp_moments_varcov,np.diag([0.0109**2]))  \n",
    "W = np.linalg.inv(np.diag(np.diag(emp_moments_varcov)))                  "
   ],
   "id": "81903ec1a634d590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:39:24.056093Z",
     "start_time": "2025-10-08T16:39:24.034011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# I separately generate moments for lying, a complex behavior that is motivated by multiple treatments\n",
    "import numpy as np\n",
    "def calculate_lying_moments_from_decisions(voter_results, nonvoter_results, treatments):\n",
    "    \"\"\"Calculate 8 lying moments from individual lying decisions\"\"\"\n",
    "    lying_moments = []\n",
    "    short_surveys = ['0d5m', '10d5m']\n",
    "    long_surveys = ['10d10m']\n",
    "    \n",
    "    def aggregate_lying_rate(results_dict, survey_list, lie_type):\n",
    "        total_psv = 0\n",
    "        total_psvl = 0\n",
    "        \n",
    "        for survey_type in survey_list:\n",
    "            if survey_type in results_dict:\n",
    "                survey_res = results_dict[survey_type]\n",
    "                if 'lying_decisions' in survey_res:\n",
    "                    lying_decisions = survey_res['lying_decisions'][lie_type]\n",
    "                    \n",
    "                    for treatment in treatments:\n",
    "                        for info_type in ['NI', 'I']:\n",
    "                            if (treatment in survey_res['PSV'] and \n",
    "                                info_type in survey_res['PSV'][treatment]):\n",
    "                                psv = survey_res['PSV'][treatment][info_type]\n",
    "                                psvl = psv * np.mean(lying_decisions)\n",
    "                                total_psv += psv\n",
    "                                total_psvl += psvl\n",
    "        \n",
    "        return total_psvl / total_psv if total_psv > 0 else 0\n",
    "    \n",
    "    # 8 lying moments\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, short_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, short_surveys, '5d1m'))\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, long_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, long_surveys, '8m'))\n",
    "    \n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, short_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, short_surveys, '5d1m'))\n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, long_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, long_surveys, '8m'))\n",
    "    \n",
    "    return lying_moments\n",
    "\n",
    "# Main function in this part, modeling individual decisions and generate group moments\n",
    "def voteSimEndogenousVoting_vary(parameters, rand_set):\n",
    "    # These are constants drawn from paper's appendix\n",
    "    N = 5.4\n",
    "    N_P = 10.1\n",
    "    \n",
    "    # Parse parameters, there are 20 in total for estimation\n",
    "    params = {\n",
    "        'h0_v': parameters[0], 'h0_nv': parameters[1],\n",
    "        'r_v': parameters[2], 'r_nv': parameters[3], \n",
    "        'eta_v': parameters[4], 'eta_nv': parameters[5],\n",
    "        'mu_s_v': parameters[6], 'mu_s_nv': parameters[7],\n",
    "        'sigma_s_v': parameters[8], 'sigma_s_nv': parameters[9],\n",
    "        'S_svy_v': parameters[10], 'S_svy_nv': parameters[11],\n",
    "        'timeval_v': parameters[12], 'timeval_nv': parameters[13],\n",
    "        'mu_sv': parameters[14], 'mu_sn': parameters[15],\n",
    "        'sigma_svn': parameters[16], 'L': parameters[17],\n",
    "        'mu_eps': parameters[18], 'sigma_eps': parameters[19]\n",
    "    }\n",
    "    \n",
    "    # Generate randomness that creates variation \n",
    "    eps = params['mu_eps'] + params['sigma_eps'] * rand_set[1]\n",
    "    sv = params['mu_sv'] + params['sigma_svn'] * rand_set[2]\n",
    "    sn = params['mu_sn'] + params['sigma_svn'] * rand_set[3]\n",
    "    \n",
    "    # Voting behavior: Sv Sn stands for social value of (non) voting\n",
    "    sigVal = np.maximum(sv, sn - params['L']) - np.maximum(sn, sv - params['L'])\n",
    "    voted = ((sigVal * N + eps) > 0).astype(int)\n",
    "    \n",
    "    # Turnout rates\n",
    "    turnout_control = np.mean(voted)\n",
    "    \n",
    "    # Survey configs: Either time incentive or momey incentive\n",
    "    survey_configs = {\n",
    "        '0d5m': {'base_reward': 0, 'time_adj_v': params['timeval_v']*5/60, \n",
    "                 'time_adj_nv': params['timeval_nv']*5/60},\n",
    "        '10d10m': {'base_reward': 10, 'time_adj_v': 0, 'time_adj_nv': 0},\n",
    "        '10d5m': {'base_reward': 10, 'time_adj_v': params['timeval_v']*5/60, \n",
    "                  'time_adj_nv': params['timeval_nv']*5/60}\n",
    "    }\n",
    "    \n",
    "    lie_incentives = {\n",
    "        'none': {'adj_v': 0, 'adj_nv': 0},\n",
    "        '5d1m': {'adj_v': 5 - params['timeval_v']/60, 'adj_nv': 5 - params['timeval_nv']/60},\n",
    "        '8m': {'adj_v': params['timeval_v']*8/60, 'adj_nv': params['timeval_nv']*8/60}\n",
    "    }\n",
    "    \n",
    "    treatments = ['NF', 'F', 'FV', 'OO', 'OOV']\n",
    "    \n",
    "    # Here I stimulate behavior of voters and non-voters for further aggregation\n",
    "    def compute_moments_for_group(voter_mask, voter_type):\n",
    "        group_data = {}\n",
    "        n_group = np.sum(voter_mask)\n",
    "        \n",
    "        if n_group == 0:\n",
    "            return {key: np.zeros(len(survey_configs)) for key in treatments}\n",
    "        \n",
    "        h0 = params[f'h0_{voter_type}']\n",
    "        r = params[f'r_{voter_type}']\n",
    "        eta = params[f'eta_{voter_type}']\n",
    "        s_svy = params[f'S_svy_{voter_type}']\n",
    "        \n",
    "        mu_s = params[f'mu_s_{voter_type}']\n",
    "        sigma_s = params[f'sigma_s_{voter_type}']\n",
    "        s_group = mu_s + sigma_s * rand_set[0][voter_mask]\n",
    "        \n",
    "        sv_group = sv[voter_mask]\n",
    "        sn_group = sn[voter_mask]\n",
    "        sigVal_group = sigVal[voter_mask]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for survey_type, config in survey_configs.items():\n",
    "            survey_results = {}\n",
    "            \n",
    "            time_adj = config[f'time_adj_{voter_type}']\n",
    "            util_svy_only = s_group + config['base_reward'] + time_adj\n",
    "            \n",
    "            if voter_type == 'v':\n",
    "                util_voting_q = np.maximum(sn_group - params['L'], sv_group)\n",
    "            else:\n",
    "                util_voting_q = np.maximum(sv_group - params['L'], sn_group)\n",
    "            \n",
    "            util_svy_plus_voting = util_svy_only + util_voting_q\n",
    "            \n",
    "            does_svy_ni = util_svy_only > -s_svy\n",
    "            does_svy_i = util_svy_plus_voting > -s_svy\n",
    "            \n",
    "            anticip_util_ni = np.maximum(util_svy_only, -s_svy)\n",
    "            anticip_util_i = np.maximum(util_svy_plus_voting, -s_svy)\n",
    "            \n",
    "            opts_out_oo = anticip_util_ni < 0\n",
    "            opts_out_oov = anticip_util_i < 0\n",
    "            \n",
    "            h_star_f = np.clip(h0 + eta * anticip_util_ni, 0, 1)\n",
    "            h_star_fv = np.clip(h0 + eta * anticip_util_i, 0, 1)\n",
    "            \n",
    "            lying_decisions = {}\n",
    "            for lie_type, lie_config in lie_incentives.items():\n",
    "                if voter_type == 'v':\n",
    "                    would_lie = (sn_group - params['L'] + lie_config[f'adj_{voter_type}']) > sv_group\n",
    "                else:\n",
    "                    would_lie = (sv_group - params['L']) > (sn_group + lie_config[f'adj_{voter_type}'])\n",
    "                lying_decisions[lie_type] = would_lie\n",
    "            \n",
    "            survey_results.update({\n",
    "                'does_svy_ni': does_svy_ni, 'does_svy_i': does_svy_i,\n",
    "                'opts_out_oo': opts_out_oo, 'opts_out_oov': opts_out_oov,\n",
    "                'h_star_f': h_star_f, 'h_star_fv': h_star_fv,\n",
    "                'lying_decisions': lying_decisions\n",
    "            })\n",
    "            \n",
    "            results[survey_type] = survey_results\n",
    "            \n",
    "        return results, h0, r\n",
    "    \n",
    "    voter_mask = voted == 1\n",
    "    nonvoter_mask = voted == 0\n",
    "    \n",
    "    voter_results, h0_v, r_v = compute_moments_for_group(voter_mask, 'v')\n",
    "    nonvoter_results, h0_nv, r_nv = compute_moments_for_group(nonvoter_mask, 'nv')\n",
    "    \n",
    "    # Here I define the function that  calculate moments across voters and non-voters group\n",
    "    def calculate_treatment_moments(results_dict, h0, r, group_name):\n",
    "        moments = {}\n",
    "        \n",
    "        for survey_type in survey_configs.keys():\n",
    "            res = results_dict[survey_type]\n",
    "            \n",
    "            ph_moments = {\n",
    "                'NF': h0,\n",
    "                'F': (1-r)*h0 + r*np.mean(res['h_star_f']),\n",
    "                'FV': (1-r)*h0 + r*np.mean(res['h_star_fv']),\n",
    "                'OO': (1-r)*h0 + r*np.mean((1-res['opts_out_oo'])*res['h_star_f']),\n",
    "                'OOV': (1-r)*h0 + r*np.mean((1-res['opts_out_oov'])*res['h_star_fv'])\n",
    "            }\n",
    "            \n",
    "            psv_nf_ni = h0 * np.mean(res['does_svy_ni'])\n",
    "            psv_nf_i = h0 * np.mean(res['does_svy_i'])\n",
    "            \n",
    "            psv_moments = {\n",
    "                'NF': {'NI': psv_nf_ni, 'I': psv_nf_i},\n",
    "                'F': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean(res['h_star_f']*res['does_svy_ni']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean(res['h_star_f']*res['does_svy_i'])\n",
    "                },\n",
    "                'FV': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean(res['h_star_fv']*res['does_svy_i']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean(res['h_star_fv']*res['does_svy_i'])\n",
    "                },\n",
    "                'OO': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean((1-res['opts_out_oo'])*res['h_star_f']*res['does_svy_ni']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean((1-res['opts_out_oo'])*res['h_star_f']*res['does_svy_i'])\n",
    "                },\n",
    "                'OOV': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean((1-res['opts_out_oov'])*res['h_star_fv']*res['does_svy_i']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean((1-res['opts_out_oov'])*res['h_star_fv']*res['does_svy_i'])\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            poo_moments = {\n",
    "                'OO': h0 * r * np.mean(res['opts_out_oo']),\n",
    "                'OOV': h0 * r * np.mean(res['opts_out_oov'])\n",
    "            }\n",
    "            \n",
    "            moments[survey_type] = {\n",
    "                'PH': ph_moments,\n",
    "                'PSV': psv_moments, \n",
    "                'POO': poo_moments\n",
    "            }\n",
    "            \n",
    "        return moments\n",
    "    \n",
    "    voter_moments = calculate_treatment_moments(voter_results, h0_v, r_v, 'v')\n",
    "    nonvoter_moments = calculate_treatment_moments(nonvoter_results, h0_nv, r_nv, 'nv')\n",
    "    \n",
    "    # FIXED: Properly track indices\n",
    "    sm = np.zeros(101)\n",
    "    idx = 0\n",
    "    \n",
    "    # PH moments (0-29): 2 groups × 5 treatments × 3 surveys = 30\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in treatments:\n",
    "            for survey_type in survey_configs.keys():\n",
    "                sm[idx] = group_moments[survey_type]['PH'][treatment]\n",
    "                idx += 1\n",
    "    \n",
    "   \n",
    "    \n",
    "    # PSV moments (30-59): average across NI/I\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in treatments:\n",
    "            for survey_type in survey_configs.keys():\n",
    "                psv_ni = group_moments[survey_type]['PSV'][treatment].get('NI', 0)\n",
    "                psv_i = group_moments[survey_type]['PSV'][treatment].get('I', 0)\n",
    "                sm[idx] = np.mean([psv_ni, psv_i])\n",
    "                idx += 1\n",
    "    \n",
    "   \n",
    "    \n",
    "    # POO moments (60-71): 2 groups × 2 treatments (OO, OOV) × 3 surveys = 12\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in ['OO', 'OOV']:\n",
    "            for survey_type in survey_configs.keys():\n",
    "                sm[idx] = group_moments[survey_type]['POO'][treatment]\n",
    "                idx += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PSV by info type (72-91): 2 groups × 5 treatments × 2 info types = 20\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in treatments:\n",
    "            for info_type in ['NI', 'I']:\n",
    "                values = []\n",
    "                for survey_type in survey_configs.keys():\n",
    "                    if info_type in group_moments[survey_type]['PSV'][treatment]:\n",
    "                        values.append(group_moments[survey_type]['PSV'][treatment][info_type])\n",
    "                sm[idx] = np.mean(values) if values else 0\n",
    "                idx += 1\n",
    "    \n",
    "\n",
    "    # Lying moments (92-99): 8 moments\n",
    "    lying_moments = calculate_lying_moments_from_decisions(\n",
    "        voter_moments, nonvoter_moments, treatments\n",
    "    )\n",
    "    for moment in lying_moments:\n",
    "        sm[idx] = moment\n",
    "        idx += 1\n",
    "    \n",
    "    # Turnout (100): 1 moment\n",
    "    sm[idx] = turnout_control\n",
    "    idx += 1\n",
    "    return sm"
   ],
   "id": "d6e5da77adc3fb5d",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T01:36:33.506938Z",
     "start_time": "2025-10-05T01:36:33.485617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SMM estimation\n",
    "class SMMEstimator:\n",
    "    \n",
    "    def __init__(self, emp_moments, weighting_matrix, n_individuals=300000, seed=42, autosave_path=None):\n",
    "        self.emp_moments = np.array(emp_moments)\n",
    "        self.n_moments = len(emp_moments)\n",
    "        self.n_individuals = n_individuals\n",
    "        self.W = weighting_matrix\n",
    "        self.autosave_path = autosave_path\n",
    "        self.seed = seed \n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        self.rand_sets = self._generate_random_sets()\n",
    "        \n",
    "        np.random.seed(None)\n",
    "        \n",
    "        self.param_config = self._setup_parameter_config()\n",
    "        self.estimation_history = []\n",
    "        \n",
    "        \n",
    "       \n",
    "    #Generate consistent random draws for simulation\n",
    "    def _generate_random_sets(self):\n",
    "        return [\n",
    "            np.random.normal(0, 1, self.n_individuals),\n",
    "            np.random.normal(0, 1, self.n_individuals),\n",
    "            np.random.normal(0, 1, self.n_individuals),\n",
    "            np.random.normal(0, 1, self.n_individuals)\n",
    "        ]\n",
    "    \n",
    "    # The range of each parameter can be found in paper's appendix\n",
    "    def _setup_parameter_config(self):\n",
    "        return {\n",
    "            'names': ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "                     'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "                     'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "                     'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps'],\n",
    "            'bounds': [\n",
    "                (0.20, 0.40), (0.20, 0.40),\n",
    "                (0.20, 0.40), (0.20, 0.40),\n",
    "                (0.0, 0.5), (0.0, 0.5),\n",
    "                (-50, 0.0), (-50, 0.0),\n",
    "                (0.0, 50), (0.0, 50),\n",
    "                (0.0, 10), (0.0, 10),\n",
    "                (0.0, 100), (0.0, 100),\n",
    "                (-20, 20), (-30, 10),\n",
    "                (0.0, 30), (0.0, 20),\n",
    "                (-30, 100), (50, 200)\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # The authors only include parameters that imply a trunout rate within (0.4,0.8)\n",
    "    def generate_initial_params(self, target_turnout_range=(0.40, 0.80), max_attempts=100):\n",
    "        # Generate random initial parameters bouunded by turnout rate\n",
    "        for attempt in range(max_attempts):\n",
    "            params = []\n",
    "            for (low, high) in self.param_config['bounds']:\n",
    "                params.append(np.random.uniform(low, high))\n",
    "            params = np.array(params)\n",
    "            \n",
    "            try:\n",
    "                sim_moments = voteSimEndogenousVoting_vary(params, self.rand_sets)\n",
    "                implied_turnout = sim_moments[100]\n",
    "                \n",
    "                if target_turnout_range[0] <= implied_turnout <= target_turnout_range[1]:\n",
    "                    return params\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"Warning: Could not find parameters with turnout in {target_turnout_range} after {max_attempts} attempts\")\n",
    "        print(\"Returning random parameters without turnout constraint\")\n",
    "        params = []\n",
    "        for (low, high) in self.param_config['bounds']:\n",
    "            params.append(np.random.uniform(low, high))\n",
    "        return np.array(params)\n",
    "    \n",
    "    \n",
    "    # Define the objective function, optimal matrix as the inverse of var-cov matrix\n",
    "    def criterion_function(self, parameters):\n",
    "        try:\n",
    "            bounds = self.param_config['bounds']\n",
    "            for i, (low, high) in enumerate(bounds):\n",
    "                if parameters[i] < low or parameters[i] > high:\n",
    "                    return 1e10\n",
    "            \n",
    "            sim_moments = voteSimEndogenousVoting_vary(parameters, self.rand_sets)\n",
    "            \n",
    "            if np.any(~np.isfinite(sim_moments)):\n",
    "                return 1e10\n",
    "            \n",
    "            moment_diff = self.emp_moments - sim_moments\n",
    "            objective = moment_diff.T @ self.W @ moment_diff\n",
    "            \n",
    "            return float(objective)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in simulation: {e}\")\n",
    "            return 1e10\n",
    "        \n",
    "        \n",
    "    # I define single starting point optimization using L-BFGS-B and Nelder-Mead methods\n",
    "    def _optimize_single(self, initial_params, max_iter, verbose):\n",
    "        try:\n",
    "            result = optimize.minimize(\n",
    "                self.criterion_function,\n",
    "                initial_params,\n",
    "                method='L-BFGS-B',\n",
    "                bounds=self.param_config['bounds'],\n",
    "                options={'disp': verbose, 'maxiter': max_iter, 'ftol': 1e-8, 'gtol': 1e-8}\n",
    "            )\n",
    "            \n",
    "            if result.success or result.fun < 1e8:\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"L-BFGS-B failed: {e}\")\n",
    "        \n",
    "        try:\n",
    "            result = optimize.minimize(\n",
    "                self.criterion_function,\n",
    "                initial_params,\n",
    "                method='Nelder-Mead',\n",
    "                options={'disp': verbose, 'maxiter': max_iter, 'xatol': 1e-8, 'fatol': 1e-8, 'adaptive': True}\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed: {e}\")\n",
    "            class FailedResult:\n",
    "                def __init__(self, initial_params):\n",
    "                    self.fun = 1e10\n",
    "                    self.x = initial_params\n",
    "                    self.success = False\n",
    "                    self.nfev = 0\n",
    "            return FailedResult(initial_params)\n",
    "        \n",
    "        \n",
    "    # The iteration takes huge amount of time, so below is where I can store the results and check it anytime\n",
    "    def save_checkpoint(self, results_list, current_start, method, n_starts):\n",
    "        #Save current progress to checkpoint file\n",
    "        if self.autosave_path:\n",
    "            checkpoint = {\n",
    "                'results_list': results_list,\n",
    "                'completed_starts': current_start,\n",
    "                'total_starts': n_starts,\n",
    "                'method': method,\n",
    "                'best_so_far': min(results_list, key=lambda x: x.fun) if results_list else None,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "            try:\n",
    "                with open(self.autosave_path, 'wb') as f:\n",
    "                    pickle.dump(checkpoint, f)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not save checkpoint: {e}\")\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        if self.autosave_path and os.path.exists(self.autosave_path):\n",
    "            try:\n",
    "                with open(self.autosave_path, 'rb') as f:\n",
    "                    checkpoint = pickle.load(f)\n",
    "                print(f\"Loaded checkpoint: {checkpoint['completed_starts']}/{checkpoint['total_starts']} starts completed\")\n",
    "                return checkpoint\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load checkpoint: {e}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "# This is the main chunk of estimation\n",
    "# I use everything defined above to generate multi-start optimization\n",
    "    def estimate(self, method='multi_start', n_starts=100, max_iter=100000, verbose=True):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\"*60)\n",
    "            print(\"Starting SMM Parameter Estimation\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Method: {method}\")\n",
    "            print(f\"Number of moments: {self.n_moments}\")\n",
    "            print(f\"Number of individuals: {self.n_individuals}\")\n",
    "            print(f\"Maximum iterations: {max_iter}\")\n",
    "            if self.autosave_path:\n",
    "                print(f\"Autosave: {self.autosave_path}\")\n",
    "        \n",
    "        results_list = []\n",
    "        \n",
    "        if method == 'single_start':\n",
    "            initial_params = self.generate_initial_params()\n",
    "            if verbose:\n",
    "                print(\"Starting single optimization...\")\n",
    "            result = self._optimize_single(initial_params, max_iter, verbose)\n",
    "            results_list.append(result)\n",
    "            \n",
    "        elif method == 'multi_start':\n",
    "            if verbose:\n",
    "                print(f\"Running multi-start optimization with {n_starts} starts...\")\n",
    "            \n",
    "            for i in range(n_starts):\n",
    "                if verbose:\n",
    "                    print(f\"Start {i+1}/{n_starts}\")\n",
    "                \n",
    "                initial_params = self.generate_initial_params()\n",
    "                result = self._optimize_single(initial_params, max_iter, verbose=False)\n",
    "                results_list.append(result)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Objective: {result.fun:.6f}\")\n",
    "                \n",
    "                # Save checkpoint after each start\n",
    "                self.save_checkpoint(results_list, i+1, method, n_starts)\n",
    "        # I also include a staged approach, where each starting point is based on previous ones\n",
    "        elif method == 'staged':\n",
    "            if verbose:\n",
    "                print(\"Running staged optimization...\")\n",
    "            \n",
    "            coarse_results = []\n",
    "            for i in range(n_starts):\n",
    "                initial_params = self.generate_initial_params()\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Coarse optimization {i+1}/{n_starts}\")\n",
    "                result = self._optimize_single(initial_params, max_iter//4, verbose=False)\n",
    "                coarse_results.append(result)\n",
    "                \n",
    "                self.save_checkpoint(coarse_results, i+1, method, n_starts)\n",
    "            \n",
    "            best_coarse = min(coarse_results, key=lambda x: x.fun)\n",
    "            if verbose:\n",
    "                print(f\"Fine optimization from best (obj: {best_coarse.fun:.4f})\")\n",
    "            final_result = self._optimize_single(best_coarse.x, max_iter, verbose)\n",
    "            results_list.append(final_result)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        best_result = min(results_list, key=lambda x: x.fun)\n",
    "        \n",
    "        estimation_time = time.time() - start_time\n",
    "        self.estimation_history.append({\n",
    "            'method': method,\n",
    "            'n_starts': n_starts,\n",
    "            'best_objective': best_result.fun,\n",
    "            'best_params': best_result.x.copy(),\n",
    "            'all_results': [r.fun for r in results_list],\n",
    "            'time_elapsed': estimation_time,\n",
    "            'success': best_result.success\n",
    "        })\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\"*60)\n",
    "            print(\"Estimation Complete!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Best objective: {best_result.fun:.6f}\")\n",
    "            print(f\"Time: {estimation_time:.2f} seconds ({estimation_time/60:.1f} minutes)\")\n",
    "            print(f\"Success: {best_result.success}\")\n",
    "            print(f\"Function evaluations: {best_result.nfev}\")\n",
    "            \n",
    "            if len(results_list) > 1:\n",
    "                obj_values = [r.fun for r in results_list]\n",
    "                print(f\"Objective range: {min(obj_values):.6f} - {max(obj_values):.6f}\")\n",
    "        \n",
    "        return best_result\n",
    "    \n",
    "    \n",
    "    # Calculate SSE\n",
    "    def evaluate_fit(self, parameters=None):\n",
    "        if parameters is None:\n",
    "            if not self.estimation_history:\n",
    "                raise ValueError(\"No estimation results available\")\n",
    "            parameters = self.estimation_history[-1]['best_params']\n",
    "        \n",
    "        sim_moments = voteSimEndogenousVoting_vary(parameters, self.rand_sets)\n",
    "        moment_diff = self.emp_moments - sim_moments\n",
    "        \n",
    "        diagnostics = {\n",
    "            'objective_value': float(moment_diff.T @ self.W @ moment_diff),\n",
    "            'moment_differences': moment_diff,\n",
    "            'max_abs_diff': float(np.max(np.abs(moment_diff))),\n",
    "            'mean_abs_diff': float(np.mean(np.abs(moment_diff))),\n",
    "            'rmse': float(np.sqrt(np.mean(moment_diff**2))),\n",
    "            'max_rel_diff': float(np.max(np.abs(moment_diff / (self.emp_moments + 1e-10)))),\n",
    "            'parameters': parameters.copy()\n",
    "        }\n",
    "        \n",
    "        return sim_moments, diagnostics\n",
    "    \n",
    "    \n",
    "    #Display estimation results\n",
    "    def display_results(self, parameters=None):\n",
    "        if parameters is None:\n",
    "            if not self.estimation_history:\n",
    "                print(\"No estimation results available\")\n",
    "                return None, None\n",
    "            parameters = self.estimation_history[-1]['best_params']\n",
    "        \n",
    "        param_df = pd.DataFrame({\n",
    "            'Parameter': self.param_config['names'],\n",
    "            'Estimate': parameters,\n",
    "            'Lower_Bound': [b[0] for b in self.param_config['bounds']],\n",
    "            'Upper_Bound': [b[1] for b in self.param_config['bounds']]\n",
    "        })\n",
    "        \n",
    "        print(\"\\nEstimated Parameters:\")\n",
    "        print(\"=\"*60)\n",
    "        print(param_df.to_string(index=False, float_format='%.4f'))\n",
    "        \n",
    "        sim_moments, diagnostics = self.evaluate_fit(parameters)\n",
    "        \n",
    "        print(f\"\\nModel Fit Diagnostics:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Objective: {diagnostics['objective_value']:.6f}\")\n",
    "        print(f\"RMSE: {diagnostics['rmse']:.6f}\")\n",
    "        print(f\"Mean Absolute Diff: {diagnostics['mean_abs_diff']:.6f}\")\n",
    "        print(f\"Max Absolute Diff: {diagnostics['max_abs_diff']:.6f}\")\n",
    "        print(f\"Max Relative Diff: {diagnostics['max_rel_diff']:.4f}\")\n",
    "        \n",
    "        return param_df, diagnostics"
   ],
   "id": "138d01e1417cc003",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:34:42.308160Z",
     "start_time": "2025-10-08T16:34:17.537335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  In the paper, the authors use n_individuals=750000 and n_starts=720, which takes more than a week to finish\n",
    "# Here I just use 300000 individuals and 100 starting points to illustrate the results of each run\n",
    "\n",
    "estimator = SMMEstimator(\n",
    "    emp_moments,\n",
    "    weighting_matrix=W,\n",
    "    n_individuals=300000,\n",
    "    autosave_path='smm_checkpoint.pkl' \n",
    ")\n",
    "result = estimator.estimate(method='multi_start', n_starts=100)\n",
    "param_table, diagnostics = estimator.display_results()\n"
   ],
   "id": "6c6dcfd9ad0dede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting SMM Parameter Estimation\n",
      "============================================================\n",
      "Method: multi_start\n",
      "Number of moments: 101\n",
      "Number of individuals: 300000\n",
      "Maximum iterations: 100000\n",
      "Autosave: smm_checkpoint.pkl\n",
      "Running multi-start optimization with 100 starts...\n",
      "Start 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[81]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m#  In the paper, the authors use n_individuals=750000 and n_starts=720, which takes more than a week to finish\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# Here I just use 300000 individuals and 100 starting points to illustrate the results of each run\u001B[39;00m\n\u001B[32m      4\u001B[39m estimator = SMMEstimator(\n\u001B[32m      5\u001B[39m     emp_moments,\n\u001B[32m      6\u001B[39m     weighting_matrix=W,\n\u001B[32m      7\u001B[39m     n_individuals=\u001B[32m300000\u001B[39m,\n\u001B[32m      8\u001B[39m     autosave_path=\u001B[33m'\u001B[39m\u001B[33msmm_checkpoint.pkl\u001B[39m\u001B[33m'\u001B[39m \n\u001B[32m      9\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m result = \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mestimate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmulti_start\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_starts\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m param_table, diagnostics = estimator.display_results()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[58]\u001B[39m\u001B[32m, line 201\u001B[39m, in \u001B[36mSMMEstimator.estimate\u001B[39m\u001B[34m(self, method, n_starts, max_iter, verbose)\u001B[39m\n\u001B[32m    198\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mStart \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_starts\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    200\u001B[39m initial_params = \u001B[38;5;28mself\u001B[39m.generate_initial_params()\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_optimize_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    202\u001B[39m results_list.append(result)\n\u001B[32m    204\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[58]\u001B[39m\u001B[32m, line 107\u001B[39m, in \u001B[36mSMMEstimator._optimize_single\u001B[39m\u001B[34m(self, initial_params, max_iter, verbose)\u001B[39m\n\u001B[32m    105\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Single optimization run\"\"\"\u001B[39;00m\n\u001B[32m    106\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m107\u001B[39m     result = \u001B[43moptimize\u001B[49m\u001B[43m.\u001B[49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    108\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcriterion_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    109\u001B[39m \u001B[43m        \u001B[49m\u001B[43minitial_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    110\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mL-BFGS-B\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    111\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_config\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mbounds\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    112\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdisp\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmaxiter\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mftol\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1e-8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mgtol\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1e-8\u001B[39;49m\u001B[43m}\u001B[49m\n\u001B[32m    113\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m result.success \u001B[38;5;129;01mor\u001B[39;00m result.fun < \u001B[32m1e8\u001B[39m:\n\u001B[32m    116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001B[39m, in \u001B[36mminimize\u001B[39m\u001B[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[39m\n\u001B[32m    728\u001B[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[32m    729\u001B[39m                              **options)\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m meth == \u001B[33m'\u001B[39m\u001B[33ml-bfgs-b\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m731\u001B[39m     res = \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    732\u001B[39m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m meth == \u001B[33m'\u001B[39m\u001B[33mtnc\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m    734\u001B[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001B[32m    735\u001B[39m                         **options)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001B[39m, in \u001B[36m_minimize_lbfgsb\u001B[39m\u001B[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[39m\n\u001B[32m    401\u001B[39m task_str = task.tobytes()\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m task_str.startswith(\u001B[33mb\u001B[39m\u001B[33m'\u001B[39m\u001B[33mFG\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[32m    404\u001B[39m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[32m    405\u001B[39m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[32m    406\u001B[39m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m407\u001B[39m     f, g = \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m task_str.startswith(\u001B[33mb\u001B[39m\u001B[33m'\u001B[39m\u001B[33mNEW_X\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m    409\u001B[39m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[32m    410\u001B[39m     n_iterations += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:344\u001B[39m, in \u001B[36mScalarFunction.fun_and_grad\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    342\u001B[39m     \u001B[38;5;28mself\u001B[39m._update_x(x)\n\u001B[32m    343\u001B[39m \u001B[38;5;28mself\u001B[39m._update_fun()\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    345\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.f, \u001B[38;5;28mself\u001B[39m.g\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:306\u001B[39m, in \u001B[36mScalarFunction._update_grad\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    304\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._orig_grad \u001B[38;5;129;01min\u001B[39;00m FD_METHODS:\n\u001B[32m    305\u001B[39m     \u001B[38;5;28mself\u001B[39m._update_fun()\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m \u001B[38;5;28mself\u001B[39m.g = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_wrapped_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf0\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[38;5;28mself\u001B[39m.g_updated = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:47\u001B[39m, in \u001B[36m_wrapper_grad.<locals>.wrapped1\u001B[39m\u001B[34m(x, f0)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mwrapped1\u001B[39m(x, f0=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     46\u001B[39m     ncalls[\u001B[32m0\u001B[39m] += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapprox_derivative\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf0\u001B[49m\u001B[43m=\u001B[49m\u001B[43mf0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfinite_diff_options\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:519\u001B[39m, in \u001B[36mapprox_derivative\u001B[39m\u001B[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001B[39m\n\u001B[32m    516\u001B[39m     use_one_sided = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    518\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sparsity \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m519\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_dense_difference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun_wrapped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    520\u001B[39m \u001B[43m                             \u001B[49m\u001B[43muse_one_sided\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    521\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    522\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m issparse(sparsity) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(sparsity) == \u001B[32m2\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:592\u001B[39m, in \u001B[36m_dense_difference\u001B[39m\u001B[34m(fun, x0, f0, h, use_one_sided, method)\u001B[39m\n\u001B[32m    590\u001B[39m     x1[i] += h[i]\n\u001B[32m    591\u001B[39m     dx = x1[i] - x0[i]  \u001B[38;5;66;03m# Recompute dx as exactly representable number.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m592\u001B[39m     df = \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m)\u001B[49m - f0\n\u001B[32m    593\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m method == \u001B[33m'\u001B[39m\u001B[33m3-point\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m use_one_sided[i]:\n\u001B[32m    594\u001B[39m     x1[i] += h[i]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:470\u001B[39m, in \u001B[36mapprox_derivative.<locals>.fun_wrapped\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m    467\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m xp.isdtype(x.dtype, \u001B[33m\"\u001B[39m\u001B[33mreal floating\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    468\u001B[39m     x = xp.astype(x, x0.dtype)\n\u001B[32m--> \u001B[39m\u001B[32m470\u001B[39m f = np.atleast_1d(\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    471\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m f.ndim > \u001B[32m1\u001B[39m:\n\u001B[32m    472\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33m`fun` return value has \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    473\u001B[39m                        \u001B[33m\"\u001B[39m\u001B[33mmore than 1 dimension.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001B[39m, in \u001B[36m_wrapper_fun.<locals>.wrapped\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m     16\u001B[39m ncalls[\u001B[32m0\u001B[39m] += \u001B[32m1\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m fx = \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np.isscalar(fx):\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[58]\u001B[39m\u001B[32m, line 90\u001B[39m, in \u001B[36mSMMEstimator.criterion_function\u001B[39m\u001B[34m(self, parameters)\u001B[39m\n\u001B[32m     87\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m parameters[i] < low \u001B[38;5;129;01mor\u001B[39;00m parameters[i] > high:\n\u001B[32m     88\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m1e10\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m sim_moments = \u001B[43mvoteSimEndogenousVoting_vary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrand_sets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np.any(~np.isfinite(sim_moments)):\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m1e10\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[71]\u001B[39m\u001B[32m, line 164\u001B[39m, in \u001B[36mvoteSimEndogenousVoting_vary\u001B[39m\u001B[34m(parameters, rand_set)\u001B[39m\n\u001B[32m    161\u001B[39m nonvoter_mask = voted == \u001B[32m0\u001B[39m\n\u001B[32m    163\u001B[39m voter_results, h0_v, r_v = compute_moments_for_group(voter_mask, \u001B[33m'\u001B[39m\u001B[33mv\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m164\u001B[39m nonvoter_results, h0_nv, r_nv = \u001B[43mcompute_moments_for_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnonvoter_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    166\u001B[39m \u001B[38;5;66;03m# Here I define the function that  calculate moments across voters and non-voters group\u001B[39;00m\n\u001B[32m    167\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mcalculate_treatment_moments\u001B[39m(results_dict, h0, r, group_name):\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[71]\u001B[39m\u001B[32m, line 138\u001B[39m, in \u001B[36mvoteSimEndogenousVoting_vary.<locals>.compute_moments_for_group\u001B[39m\u001B[34m(voter_mask, voter_type)\u001B[39m\n\u001B[32m    135\u001B[39m opts_out_oo = anticip_util_ni < \u001B[32m0\u001B[39m\n\u001B[32m    136\u001B[39m opts_out_oov = anticip_util_i < \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m h_star_f = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mclip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh0\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43manticip_util_ni\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    139\u001B[39m h_star_fv = np.clip(h0 + eta * anticip_util_i, \u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m)\n\u001B[32m    141\u001B[39m lying_decisions = {}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Quant Econ\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2096\u001B[39m, in \u001B[36m_clip_dispatcher\u001B[39m\u001B[34m(a, a_min, a_max, out, **kwargs)\u001B[39m\n\u001B[32m   2034\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2035\u001B[39m \u001B[33;03m    Return selected slices of an array along given axis.\u001B[39;00m\n\u001B[32m   2036\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   2091\u001B[39m \n\u001B[32m   2092\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   2093\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapfunc(a, \u001B[33m'\u001B[39m\u001B[33mcompress\u001B[39m\u001B[33m'\u001B[39m, condition, axis=axis, out=out)\n\u001B[32m-> \u001B[39m\u001B[32m2096\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34m_clip_dispatcher\u001B[39m(a, a_min, a_max, out=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n\u001B[32m   2097\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, a_min, a_max)\n\u001B[32m   2100\u001B[39m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_clip_dispatcher)\n\u001B[32m   2101\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mclip\u001B[39m(a, a_min, a_max, out=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:13:02.755521Z",
     "start_time": "2025-10-08T16:13:02.723794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here I show my results of optimal estimation\n",
    "import pickle\n",
    "import pandas as pd\n",
    "with open('smm_checkpoint.pkl', 'rb') as f:\n",
    "    checkpoint = pickle.load(f)\n",
    "print(f\"Process: {checkpoint['completed_starts']}/{checkpoint['total_starts']}\")\n",
    "print(f\"Optimal objective: {checkpoint['best_so_far'].fun:.6f}\\n\")\n",
    "\n",
    "param_names = ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "               'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "               'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "               'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps']\n",
    "df = pd.DataFrame({\n",
    "    'Parameter': param_names,\n",
    "    'Value': checkpoint['best_so_far'].x\n",
    "})\n",
    "print(df.to_string(index=False))"
   ],
   "id": "8c8b2df85646313c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 100/100\n",
      "Optimal objective: 785.368755\n",
      "\n",
      " Parameter      Value\n",
      "      h0_v   0.372406\n",
      "     h0_nv   0.361436\n",
      "       r_v   0.376651\n",
      "      r_nv   0.292714\n",
      "     eta_v   0.145226\n",
      "    eta_nv   0.039576\n",
      "    mu_s_v -22.282835\n",
      "   mu_s_nv -38.815866\n",
      " sigma_s_v  24.442116\n",
      "sigma_s_nv  37.620765\n",
      "   S_svy_v   1.407816\n",
      "  S_svy_nv   5.086271\n",
      " timeval_v  91.398778\n",
      "timeval_nv  81.169499\n",
      "     mu_sv  -6.172388\n",
      "     mu_sn -23.334700\n",
      " sigma_svn  10.758911\n",
      "         L  14.798783\n",
      "    mu_eps -23.684616\n",
      " sigma_eps 145.616936\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:19:50.469338Z",
     "start_time": "2025-10-08T16:19:50.452816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the results\n",
    "with open('smm_checkpoint.pkl', 'rb') as f:\n",
    "    checkpoint = pickle.load(f)\n",
    "\n",
    "your_result = checkpoint['best_so_far']\n",
    "your_params = your_result.x\n",
    "your_objective = your_result.fun\n",
    "print(f\"My Optimal objective: {your_objective:.2f}\")\n",
    "\n",
    "# Comparison\n",
    "# Load the parameters based on authors estimation\n",
    "author_params = np.array([0.38,0.36,0.38,0.30,0.14,0.16,-22.6,-27.7,26.9,24.7,1.6,1.2,42.7,23.9,-3.9,-11.3,9.5,7.6,64.1,318.7]) \n",
    "\n",
    "param_names = ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "               'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "               'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "               'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps']\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Parameter': param_names,\n",
    "    'Your_Estimate': your_params,\n",
    "    'Author_Estimate': author_params,\n",
    "    'Difference': your_params - author_params,\n",
    "    'Pct_Diff': 100 * (your_params - author_params) / np.abs(author_params)\n",
    "})\n",
    "\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))\n"
   ],
   "id": "69c7d0e453366bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Optimal objective: 785.37\n",
      "\n",
      "Parameter Comparison:\n",
      " Parameter  Your_Estimate  Author_Estimate  Difference  Pct_Diff\n",
      "      h0_v         0.3724           0.3800     -0.0076   -1.9985\n",
      "     h0_nv         0.3614           0.3600      0.0014    0.3988\n",
      "       r_v         0.3767           0.3800     -0.0033   -0.8812\n",
      "      r_nv         0.2927           0.3000     -0.0073   -2.4288\n",
      "     eta_v         0.1452           0.1400      0.0052    3.7332\n",
      "    eta_nv         0.0396           0.1600     -0.1204  -75.2651\n",
      "    mu_s_v       -22.2828         -22.6000      0.3172    1.4034\n",
      "   mu_s_nv       -38.8159         -27.7000    -11.1159  -40.1295\n",
      " sigma_s_v        24.4421          26.9000     -2.4579   -9.1371\n",
      "sigma_s_nv        37.6208          24.7000     12.9208   52.3108\n",
      "   S_svy_v         1.4078           1.6000     -0.1922  -12.0115\n",
      "  S_svy_nv         5.0863           1.2000      3.8863  323.8559\n",
      " timeval_v        91.3988          42.7000     48.6988  114.0487\n",
      "timeval_nv        81.1695          23.9000     57.2695  239.6213\n",
      "     mu_sv        -6.1724          -3.9000     -2.2724  -58.2664\n",
      "     mu_sn       -23.3347         -11.3000    -12.0347 -106.5018\n",
      " sigma_svn        10.7589           9.5000      1.2589   13.2517\n",
      "         L        14.7988           7.6000      7.1988   94.7208\n",
      "    mu_eps       -23.6846          64.1000    -87.7846 -136.9495\n",
      " sigma_eps       145.6169         318.7000   -173.0831  -54.3091\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:06:05.696678Z",
     "start_time": "2025-10-08T17:06:05.677239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here I try to use different n_individuals and n_starting points, and compare its results with my set up, to see if the estimation is sensitive on the choice of n_individuals and n_starting points \n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    with open('checkpoint_full_720.pkl', 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "    \n",
    "    print(f\"Process: {checkpoint['completed_starts']}/{checkpoint['total_starts']}\")\n",
    "    print(f\"Optimal SSE: {checkpoint['best_so_far'].fun:.2f}\")\n",
    "    print(f\"Authors' SSE:160.3\")\n",
    "    \n",
    "    # Display optimal parameters\n",
    "    best_params = checkpoint['best_so_far'].x\n",
    "    param_names = ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "                   'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "                   'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "                   'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps']\n",
    "    \n",
    "    param_df = pd.DataFrame({\n",
    "        'Parameter': param_names,\n",
    "        'Value': best_params\n",
    "    })\n",
    "    \n",
    "    print(\"\\nOptimal Parameters:\")\n",
    "    print(param_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Display the best 5 SSE\n",
    "    all_obj = [r.fun for r in checkpoint['results_list']]\n",
    "    print(f\"\\nFirst 5 best SSE: {sorted(all_obj)[:5]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "f14c7ae7fa3da6fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 128/720\n",
      "Optimal SSE: 789.59\n",
      "Authors' SSE:160.3\n",
      "\n",
      "Optimal Parameters:\n",
      " Parameter    Value\n",
      "      h0_v   0.3723\n",
      "     h0_nv   0.3580\n",
      "       r_v   0.3690\n",
      "      r_nv   0.3005\n",
      "     eta_v   0.0471\n",
      "    eta_nv   0.0977\n",
      "    mu_s_v -31.6940\n",
      "   mu_s_nv -39.7325\n",
      " sigma_s_v  47.9692\n",
      "sigma_s_nv  38.8627\n",
      "   S_svy_v   4.0562\n",
      "  S_svy_nv   1.9352\n",
      " timeval_v  63.8924\n",
      "timeval_nv  68.6511\n",
      "     mu_sv  -6.0485\n",
      "     mu_sn -11.8061\n",
      " sigma_svn   2.2204\n",
      "         L  19.4944\n",
      "    mu_eps  -6.6863\n",
      " sigma_eps 158.8788\n",
      "\n",
      "First 5 best SSE: [789.58978505024, 792.4326380990643, 801.0998617341428, 806.1569423851921, 808.1385220021207]\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comments:\n",
    "(i) The estimation result is relatively stable when I change: n_individuals, n_starting points, as well as when I try different optimization\n",
    "methods.\n",
    "\n",
    "(ii) As I increase the size of n_individuals and n_starting points, the results of my estimation becomes closer to authors'results.\n"
   ],
   "id": "71f8f46205784e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
