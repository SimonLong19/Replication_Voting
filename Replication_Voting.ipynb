{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Yiteng Long (Simon)'s Replication: \n",
    "SMM estimation in DellaVigna, List, Malmendier and Rao, 2017, \"Voting To Tell Others\""
   ],
   "id": "cd65a42602a21882"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 86,
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "from scipy.linalg import block_diag\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "# Import the empirical moments \n",
    "# I add baseline turnnout rate and flatten the imported data\n",
    "dt_empmoments = loadmat('d:/Users/29457/Desktop/26Fall/Coding Sample/Moments.mat')                         \n",
    "emp_moments = [dt_empmoments[\"Moments\"]]\n",
    "emp_moments = [item for sublist in emp_moments for item in sublist]       \n",
    "emp_moments.append(np.array([0.6000]))                                    \n",
    "emp_moments = np.ndarray.flatten(np.array(emp_moments))        \n",
    "\n",
    "# Import empirical var-cov matrix; 101 moments\n",
    "# W is the inverse, used as weighting matrix in SMM\n",
    "emp_moments_varcov =  dt_empmoments[\"VCcontrol\"]                          \n",
    "emp_moments_varcov = block_diag(emp_moments_varcov,np.diag([0.0109**2]))  \n",
    "W = np.linalg.inv(np.diag(np.diag(emp_moments_varcov)))                  "
   ],
   "id": "81903ec1a634d590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:39:24.056093Z",
     "start_time": "2025-10-08T16:39:24.034011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# I separately generate moments for lying, a complex behavior that is motivated by multiple treatments\n",
    "import numpy as np\n",
    "def calculate_lying_moments_from_decisions(voter_results, nonvoter_results, treatments):\n",
    "    \"\"\"Calculate 8 lying moments from individual lying decisions\"\"\"\n",
    "    lying_moments = []\n",
    "    short_surveys = ['0d5m', '10d5m']\n",
    "    long_surveys = ['10d10m']\n",
    "    \n",
    "    def aggregate_lying_rate(results_dict, survey_list, lie_type):\n",
    "        total_psv = 0\n",
    "        total_psvl = 0\n",
    "        \n",
    "        for survey_type in survey_list:\n",
    "            if survey_type in results_dict:\n",
    "                survey_res = results_dict[survey_type]\n",
    "                if 'lying_decisions' in survey_res:\n",
    "                    lying_decisions = survey_res['lying_decisions'][lie_type]\n",
    "                    \n",
    "                    for treatment in treatments:\n",
    "                        for info_type in ['NI', 'I']:\n",
    "                            if (treatment in survey_res['PSV'] and \n",
    "                                info_type in survey_res['PSV'][treatment]):\n",
    "                                psv = survey_res['PSV'][treatment][info_type]\n",
    "                                psvl = psv * np.mean(lying_decisions)\n",
    "                                total_psv += psv\n",
    "                                total_psvl += psvl\n",
    "        \n",
    "        return total_psvl / total_psv if total_psv > 0 else 0\n",
    "    \n",
    "    # 8 lying moments\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, short_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, short_surveys, '5d1m'))\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, long_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(voter_results, long_surveys, '8m'))\n",
    "    \n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, short_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, short_surveys, '5d1m'))\n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, long_surveys, 'none'))\n",
    "    lying_moments.append(aggregate_lying_rate(nonvoter_results, long_surveys, '8m'))\n",
    "    \n",
    "    return lying_moments\n",
    "\n",
    "# Main function in this part, modeling individual decisions and generate group moments\n",
    "def voteSimEndogenousVoting_vary(parameters, rand_set):\n",
    "    # These are constants drawn from paper's appendix\n",
    "    N = 5.4\n",
    "    N_P = 10.1\n",
    "    \n",
    "    # Parse parameters, there are 20 in total for estimation\n",
    "    params = {\n",
    "        'h0_v': parameters[0], 'h0_nv': parameters[1],\n",
    "        'r_v': parameters[2], 'r_nv': parameters[3], \n",
    "        'eta_v': parameters[4], 'eta_nv': parameters[5],\n",
    "        'mu_s_v': parameters[6], 'mu_s_nv': parameters[7],\n",
    "        'sigma_s_v': parameters[8], 'sigma_s_nv': parameters[9],\n",
    "        'S_svy_v': parameters[10], 'S_svy_nv': parameters[11],\n",
    "        'timeval_v': parameters[12], 'timeval_nv': parameters[13],\n",
    "        'mu_sv': parameters[14], 'mu_sn': parameters[15],\n",
    "        'sigma_svn': parameters[16], 'L': parameters[17],\n",
    "        'mu_eps': parameters[18], 'sigma_eps': parameters[19]\n",
    "    }\n",
    "    \n",
    "    # Generate randomness that creates variation \n",
    "    eps = params['mu_eps'] + params['sigma_eps'] * rand_set[1]\n",
    "    sv = params['mu_sv'] + params['sigma_svn'] * rand_set[2]\n",
    "    sn = params['mu_sn'] + params['sigma_svn'] * rand_set[3]\n",
    "    \n",
    "    # Voting behavior: Sv Sn stands for social value of (non) voting\n",
    "    sigVal = np.maximum(sv, sn - params['L']) - np.maximum(sn, sv - params['L'])\n",
    "    voted = ((sigVal * N + eps) > 0).astype(int)\n",
    "    \n",
    "    # Turnout rates\n",
    "    turnout_control = np.mean(voted)\n",
    "    \n",
    "    # Survey configs: Either time incentive or momey incentive\n",
    "    survey_configs = {\n",
    "        '0d5m': {'base_reward': 0, 'time_adj_v': params['timeval_v']*5/60, \n",
    "                 'time_adj_nv': params['timeval_nv']*5/60},\n",
    "        '10d10m': {'base_reward': 10, 'time_adj_v': 0, 'time_adj_nv': 0},\n",
    "        '10d5m': {'base_reward': 10, 'time_adj_v': params['timeval_v']*5/60, \n",
    "                  'time_adj_nv': params['timeval_nv']*5/60}\n",
    "    }\n",
    "    \n",
    "    lie_incentives = {\n",
    "        'none': {'adj_v': 0, 'adj_nv': 0},\n",
    "        '5d1m': {'adj_v': 5 - params['timeval_v']/60, 'adj_nv': 5 - params['timeval_nv']/60},\n",
    "        '8m': {'adj_v': params['timeval_v']*8/60, 'adj_nv': params['timeval_nv']*8/60}\n",
    "    }\n",
    "    \n",
    "    treatments = ['NF', 'F', 'FV', 'OO', 'OOV']\n",
    "    \n",
    "    # Here I stimulate behavior of voters and non-voters for further aggregation\n",
    "    def compute_moments_for_group(voter_mask, voter_type):\n",
    "        group_data = {}\n",
    "        n_group = np.sum(voter_mask)\n",
    "        \n",
    "        if n_group == 0:\n",
    "            return {key: np.zeros(len(survey_configs)) for key in treatments}\n",
    "        \n",
    "        h0 = params[f'h0_{voter_type}']\n",
    "        r = params[f'r_{voter_type}']\n",
    "        eta = params[f'eta_{voter_type}']\n",
    "        s_svy = params[f'S_svy_{voter_type}']\n",
    "        \n",
    "        mu_s = params[f'mu_s_{voter_type}']\n",
    "        sigma_s = params[f'sigma_s_{voter_type}']\n",
    "        s_group = mu_s + sigma_s * rand_set[0][voter_mask]\n",
    "        \n",
    "        sv_group = sv[voter_mask]\n",
    "        sn_group = sn[voter_mask]\n",
    "        sigVal_group = sigVal[voter_mask]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for survey_type, config in survey_configs.items():\n",
    "            survey_results = {}\n",
    "            \n",
    "            time_adj = config[f'time_adj_{voter_type}']\n",
    "            util_svy_only = s_group + config['base_reward'] + time_adj\n",
    "            \n",
    "            if voter_type == 'v':\n",
    "                util_voting_q = np.maximum(sn_group - params['L'], sv_group)\n",
    "            else:\n",
    "                util_voting_q = np.maximum(sv_group - params['L'], sn_group)\n",
    "            \n",
    "            util_svy_plus_voting = util_svy_only + util_voting_q\n",
    "            \n",
    "            does_svy_ni = util_svy_only > -s_svy\n",
    "            does_svy_i = util_svy_plus_voting > -s_svy\n",
    "            \n",
    "            anticip_util_ni = np.maximum(util_svy_only, -s_svy)\n",
    "            anticip_util_i = np.maximum(util_svy_plus_voting, -s_svy)\n",
    "            \n",
    "            opts_out_oo = anticip_util_ni < 0\n",
    "            opts_out_oov = anticip_util_i < 0\n",
    "            \n",
    "            h_star_f = np.clip(h0 + eta * anticip_util_ni, 0, 1)\n",
    "            h_star_fv = np.clip(h0 + eta * anticip_util_i, 0, 1)\n",
    "            \n",
    "            lying_decisions = {}\n",
    "            for lie_type, lie_config in lie_incentives.items():\n",
    "                if voter_type == 'v':\n",
    "                    would_lie = (sn_group - params['L'] + lie_config[f'adj_{voter_type}']) > sv_group\n",
    "                else:\n",
    "                    would_lie = (sv_group - params['L']) > (sn_group + lie_config[f'adj_{voter_type}'])\n",
    "                lying_decisions[lie_type] = would_lie\n",
    "            \n",
    "            survey_results.update({\n",
    "                'does_svy_ni': does_svy_ni, 'does_svy_i': does_svy_i,\n",
    "                'opts_out_oo': opts_out_oo, 'opts_out_oov': opts_out_oov,\n",
    "                'h_star_f': h_star_f, 'h_star_fv': h_star_fv,\n",
    "                'lying_decisions': lying_decisions\n",
    "            })\n",
    "            \n",
    "            results[survey_type] = survey_results\n",
    "            \n",
    "        return results, h0, r\n",
    "    \n",
    "    voter_mask = voted == 1\n",
    "    nonvoter_mask = voted == 0\n",
    "    \n",
    "    voter_results, h0_v, r_v = compute_moments_for_group(voter_mask, 'v')\n",
    "    nonvoter_results, h0_nv, r_nv = compute_moments_for_group(nonvoter_mask, 'nv')\n",
    "    \n",
    "    # Here I define the function that  calculate moments across voters and non-voters group\n",
    "    def calculate_treatment_moments(results_dict, h0, r, group_name):\n",
    "        moments = {}\n",
    "        \n",
    "        for survey_type in survey_configs.keys():\n",
    "            res = results_dict[survey_type]\n",
    "            \n",
    "            ph_moments = {\n",
    "                'NF': h0,\n",
    "                'F': (1-r)*h0 + r*np.mean(res['h_star_f']),\n",
    "                'FV': (1-r)*h0 + r*np.mean(res['h_star_fv']),\n",
    "                'OO': (1-r)*h0 + r*np.mean((1-res['opts_out_oo'])*res['h_star_f']),\n",
    "                'OOV': (1-r)*h0 + r*np.mean((1-res['opts_out_oov'])*res['h_star_fv'])\n",
    "            }\n",
    "            \n",
    "            psv_nf_ni = h0 * np.mean(res['does_svy_ni'])\n",
    "            psv_nf_i = h0 * np.mean(res['does_svy_i'])\n",
    "            \n",
    "            psv_moments = {\n",
    "                'NF': {'NI': psv_nf_ni, 'I': psv_nf_i},\n",
    "                'F': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean(res['h_star_f']*res['does_svy_ni']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean(res['h_star_f']*res['does_svy_i'])\n",
    "                },\n",
    "                'FV': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean(res['h_star_fv']*res['does_svy_i']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean(res['h_star_fv']*res['does_svy_i'])\n",
    "                },\n",
    "                'OO': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean((1-res['opts_out_oo'])*res['h_star_f']*res['does_svy_ni']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean((1-res['opts_out_oo'])*res['h_star_f']*res['does_svy_i'])\n",
    "                },\n",
    "                'OOV': {\n",
    "                    'NI': (1-r)*psv_nf_ni + r*np.mean((1-res['opts_out_oov'])*res['h_star_fv']*res['does_svy_i']),\n",
    "                    'I': (1-r)*psv_nf_i + r*np.mean((1-res['opts_out_oov'])*res['h_star_fv']*res['does_svy_i'])\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            poo_moments = {\n",
    "                'OO': h0 * r * np.mean(res['opts_out_oo']),\n",
    "                'OOV': h0 * r * np.mean(res['opts_out_oov'])\n",
    "            }\n",
    "            \n",
    "            moments[survey_type] = {\n",
    "                'PH': ph_moments,\n",
    "                'PSV': psv_moments, \n",
    "                'POO': poo_moments\n",
    "            }\n",
    "            \n",
    "        return moments\n",
    "    \n",
    "    voter_moments = calculate_treatment_moments(voter_results, h0_v, r_v, 'v')\n",
    "    nonvoter_moments = calculate_treatment_moments(nonvoter_results, h0_nv, r_nv, 'nv')\n",
    "    \n",
    "    # FIXED: Properly track indices\n",
    "    sm = np.zeros(101)\n",
    "    idx = 0\n",
    "    \n",
    "    # PH moments (0-29): 2 groups × 5 treatments × 3 surveys = 30\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in treatments:\n",
    "            for survey_type in survey_configs.keys():\n",
    "                sm[idx] = group_moments[survey_type]['PH'][treatment]\n",
    "                idx += 1\n",
    "    \n",
    "   \n",
    "    \n",
    "    # PSV moments (30-59): average across NI/I\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in treatments:\n",
    "            for survey_type in survey_configs.keys():\n",
    "                psv_ni = group_moments[survey_type]['PSV'][treatment].get('NI', 0)\n",
    "                psv_i = group_moments[survey_type]['PSV'][treatment].get('I', 0)\n",
    "                sm[idx] = np.mean([psv_ni, psv_i])\n",
    "                idx += 1\n",
    "    \n",
    "   \n",
    "    \n",
    "    # POO moments (60-71): 2 groups × 2 treatments (OO, OOV) × 3 surveys = 12\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in ['OO', 'OOV']:\n",
    "            for survey_type in survey_configs.keys():\n",
    "                sm[idx] = group_moments[survey_type]['POO'][treatment]\n",
    "                idx += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PSV by info type (72-91): 2 groups × 5 treatments × 2 info types = 20\n",
    "    for group_moments in [voter_moments, nonvoter_moments]:\n",
    "        for treatment in treatments:\n",
    "            for info_type in ['NI', 'I']:\n",
    "                values = []\n",
    "                for survey_type in survey_configs.keys():\n",
    "                    if info_type in group_moments[survey_type]['PSV'][treatment]:\n",
    "                        values.append(group_moments[survey_type]['PSV'][treatment][info_type])\n",
    "                sm[idx] = np.mean(values) if values else 0\n",
    "                idx += 1\n",
    "    \n",
    "\n",
    "    # Lying moments (92-99): 8 moments\n",
    "    lying_moments = calculate_lying_moments_from_decisions(\n",
    "        voter_moments, nonvoter_moments, treatments\n",
    "    )\n",
    "    for moment in lying_moments:\n",
    "        sm[idx] = moment\n",
    "        idx += 1\n",
    "    \n",
    "    # Turnout (100): 1 moment\n",
    "    sm[idx] = turnout_control\n",
    "    idx += 1\n",
    "    return sm"
   ],
   "id": "d6e5da77adc3fb5d",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T01:36:33.506938Z",
     "start_time": "2025-10-05T01:36:33.485617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SMM estimation\n",
    "class SMMEstimator:\n",
    "    \n",
    "    def __init__(self, emp_moments, weighting_matrix, n_individuals=300000, seed=42, autosave_path=None):\n",
    "        self.emp_moments = np.array(emp_moments)\n",
    "        self.n_moments = len(emp_moments)\n",
    "        self.n_individuals = n_individuals\n",
    "        self.W = weighting_matrix\n",
    "        self.autosave_path = autosave_path\n",
    "        self.seed = seed \n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        self.rand_sets = self._generate_random_sets()\n",
    "        \n",
    "        np.random.seed(None)\n",
    "        \n",
    "        self.param_config = self._setup_parameter_config()\n",
    "        self.estimation_history = []\n",
    "        \n",
    "        \n",
    "       \n",
    "    #Generate consistent random draws for simulation\n",
    "    def _generate_random_sets(self):\n",
    "        return [\n",
    "            np.random.normal(0, 1, self.n_individuals),\n",
    "            np.random.normal(0, 1, self.n_individuals),\n",
    "            np.random.normal(0, 1, self.n_individuals),\n",
    "            np.random.normal(0, 1, self.n_individuals)\n",
    "        ]\n",
    "    \n",
    "    # The range of each parameter can be found in paper's appendix\n",
    "    def _setup_parameter_config(self):\n",
    "        return {\n",
    "            'names': ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "                     'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "                     'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "                     'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps'],\n",
    "            'bounds': [\n",
    "                (0.20, 0.40), (0.20, 0.40),\n",
    "                (0.20, 0.40), (0.20, 0.40),\n",
    "                (0.0, 0.5), (0.0, 0.5),\n",
    "                (-50, 0.0), (-50, 0.0),\n",
    "                (0.0, 50), (0.0, 50),\n",
    "                (0.0, 10), (0.0, 10),\n",
    "                (0.0, 100), (0.0, 100),\n",
    "                (-20, 20), (-30, 10),\n",
    "                (0.0, 30), (0.0, 20),\n",
    "                (-30, 100), (50, 200)\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # The authors only include parameters that imply a trunout rate within (0.4,0.8)\n",
    "    def generate_initial_params(self, target_turnout_range=(0.40, 0.80), max_attempts=100):\n",
    "        # Generate random initial parameters bouunded by turnout rate\n",
    "        for attempt in range(max_attempts):\n",
    "            params = []\n",
    "            for (low, high) in self.param_config['bounds']:\n",
    "                params.append(np.random.uniform(low, high))\n",
    "            params = np.array(params)\n",
    "            \n",
    "            try:\n",
    "                sim_moments = voteSimEndogenousVoting_vary(params, self.rand_sets)\n",
    "                implied_turnout = sim_moments[100]\n",
    "                \n",
    "                if target_turnout_range[0] <= implied_turnout <= target_turnout_range[1]:\n",
    "                    return params\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"Warning: Could not find parameters with turnout in {target_turnout_range} after {max_attempts} attempts\")\n",
    "        print(\"Returning random parameters without turnout constraint\")\n",
    "        params = []\n",
    "        for (low, high) in self.param_config['bounds']:\n",
    "            params.append(np.random.uniform(low, high))\n",
    "        return np.array(params)\n",
    "    \n",
    "    \n",
    "    # Define the objective function, optimal matrix as the inverse of var-cov matrix\n",
    "    def criterion_function(self, parameters):\n",
    "        try:\n",
    "            bounds = self.param_config['bounds']\n",
    "            for i, (low, high) in enumerate(bounds):\n",
    "                if parameters[i] < low or parameters[i] > high:\n",
    "                    return 1e10\n",
    "            \n",
    "            sim_moments = voteSimEndogenousVoting_vary(parameters, self.rand_sets)\n",
    "            \n",
    "            if np.any(~np.isfinite(sim_moments)):\n",
    "                return 1e10\n",
    "            \n",
    "            moment_diff = self.emp_moments - sim_moments\n",
    "            objective = moment_diff.T @ self.W @ moment_diff\n",
    "            \n",
    "            return float(objective)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in simulation: {e}\")\n",
    "            return 1e10\n",
    "        \n",
    "        \n",
    "    # I define single starting point optimization using L-BFGS-B and Nelder-Mead methods\n",
    "    def _optimize_single(self, initial_params, max_iter, verbose):\n",
    "        try:\n",
    "            result = optimize.minimize(\n",
    "                self.criterion_function,\n",
    "                initial_params,\n",
    "                method='L-BFGS-B',\n",
    "                bounds=self.param_config['bounds'],\n",
    "                options={'disp': verbose, 'maxiter': max_iter, 'ftol': 1e-8, 'gtol': 1e-8}\n",
    "            )\n",
    "            \n",
    "            if result.success or result.fun < 1e8:\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"L-BFGS-B failed: {e}\")\n",
    "        \n",
    "        try:\n",
    "            result = optimize.minimize(\n",
    "                self.criterion_function,\n",
    "                initial_params,\n",
    "                method='Nelder-Mead',\n",
    "                options={'disp': verbose, 'maxiter': max_iter, 'xatol': 1e-8, 'fatol': 1e-8, 'adaptive': True}\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed: {e}\")\n",
    "            class FailedResult:\n",
    "                def __init__(self, initial_params):\n",
    "                    self.fun = 1e10\n",
    "                    self.x = initial_params\n",
    "                    self.success = False\n",
    "                    self.nfev = 0\n",
    "            return FailedResult(initial_params)\n",
    "        \n",
    "        \n",
    "    # The iteration takes huge amount of time, so below is where I can store the results and check it anytime\n",
    "    def save_checkpoint(self, results_list, current_start, method, n_starts):\n",
    "        #Save current progress to checkpoint file\n",
    "        if self.autosave_path:\n",
    "            checkpoint = {\n",
    "                'results_list': results_list,\n",
    "                'completed_starts': current_start,\n",
    "                'total_starts': n_starts,\n",
    "                'method': method,\n",
    "                'best_so_far': min(results_list, key=lambda x: x.fun) if results_list else None,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "            try:\n",
    "                with open(self.autosave_path, 'wb') as f:\n",
    "                    pickle.dump(checkpoint, f)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not save checkpoint: {e}\")\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        if self.autosave_path and os.path.exists(self.autosave_path):\n",
    "            try:\n",
    "                with open(self.autosave_path, 'rb') as f:\n",
    "                    checkpoint = pickle.load(f)\n",
    "                print(f\"Loaded checkpoint: {checkpoint['completed_starts']}/{checkpoint['total_starts']} starts completed\")\n",
    "                return checkpoint\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load checkpoint: {e}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "# This is the main chunk of estimation\n",
    "# I use everything defined above to generate multi-start optimization\n",
    "    def estimate(self, method='multi_start', n_starts=100, max_iter=100000, verbose=True):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\"*60)\n",
    "            print(\"Starting SMM Parameter Estimation\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Method: {method}\")\n",
    "            print(f\"Number of moments: {self.n_moments}\")\n",
    "            print(f\"Number of individuals: {self.n_individuals}\")\n",
    "            print(f\"Maximum iterations: {max_iter}\")\n",
    "            if self.autosave_path:\n",
    "                print(f\"Autosave: {self.autosave_path}\")\n",
    "        \n",
    "        results_list = []\n",
    "        \n",
    "        if method == 'single_start':\n",
    "            initial_params = self.generate_initial_params()\n",
    "            if verbose:\n",
    "                print(\"Starting single optimization...\")\n",
    "            result = self._optimize_single(initial_params, max_iter, verbose)\n",
    "            results_list.append(result)\n",
    "            \n",
    "        elif method == 'multi_start':\n",
    "            if verbose:\n",
    "                print(f\"Running multi-start optimization with {n_starts} starts...\")\n",
    "            \n",
    "            for i in range(n_starts):\n",
    "                if verbose:\n",
    "                    print(f\"Start {i+1}/{n_starts}\")\n",
    "                \n",
    "                initial_params = self.generate_initial_params()\n",
    "                result = self._optimize_single(initial_params, max_iter, verbose=False)\n",
    "                results_list.append(result)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Objective: {result.fun:.6f}\")\n",
    "                \n",
    "                # Save checkpoint after each start\n",
    "                self.save_checkpoint(results_list, i+1, method, n_starts)\n",
    "        # I also include a staged approach, where each starting point is based on previous ones\n",
    "        elif method == 'staged':\n",
    "            if verbose:\n",
    "                print(\"Running staged optimization...\")\n",
    "            \n",
    "            coarse_results = []\n",
    "            for i in range(n_starts):\n",
    "                initial_params = self.generate_initial_params()\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Coarse optimization {i+1}/{n_starts}\")\n",
    "                result = self._optimize_single(initial_params, max_iter//4, verbose=False)\n",
    "                coarse_results.append(result)\n",
    "                \n",
    "                self.save_checkpoint(coarse_results, i+1, method, n_starts)\n",
    "            \n",
    "            best_coarse = min(coarse_results, key=lambda x: x.fun)\n",
    "            if verbose:\n",
    "                print(f\"Fine optimization from best (obj: {best_coarse.fun:.4f})\")\n",
    "            final_result = self._optimize_single(best_coarse.x, max_iter, verbose)\n",
    "            results_list.append(final_result)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        best_result = min(results_list, key=lambda x: x.fun)\n",
    "        \n",
    "        estimation_time = time.time() - start_time\n",
    "        self.estimation_history.append({\n",
    "            'method': method,\n",
    "            'n_starts': n_starts,\n",
    "            'best_objective': best_result.fun,\n",
    "            'best_params': best_result.x.copy(),\n",
    "            'all_results': [r.fun for r in results_list],\n",
    "            'time_elapsed': estimation_time,\n",
    "            'success': best_result.success\n",
    "        })\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\"*60)\n",
    "            print(\"Estimation Complete!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Best objective: {best_result.fun:.6f}\")\n",
    "            print(f\"Time: {estimation_time:.2f} seconds ({estimation_time/60:.1f} minutes)\")\n",
    "            print(f\"Success: {best_result.success}\")\n",
    "            print(f\"Function evaluations: {best_result.nfev}\")\n",
    "            \n",
    "            if len(results_list) > 1:\n",
    "                obj_values = [r.fun for r in results_list]\n",
    "                print(f\"Objective range: {min(obj_values):.6f} - {max(obj_values):.6f}\")\n",
    "        \n",
    "        return best_result\n",
    "    \n",
    "    \n",
    "    # Calculate SSE\n",
    "    def evaluate_fit(self, parameters=None):\n",
    "        if parameters is None:\n",
    "            if not self.estimation_history:\n",
    "                raise ValueError(\"No estimation results available\")\n",
    "            parameters = self.estimation_history[-1]['best_params']\n",
    "        \n",
    "        sim_moments = voteSimEndogenousVoting_vary(parameters, self.rand_sets)\n",
    "        moment_diff = self.emp_moments - sim_moments\n",
    "        \n",
    "        diagnostics = {\n",
    "            'objective_value': float(moment_diff.T @ self.W @ moment_diff),\n",
    "            'moment_differences': moment_diff,\n",
    "            'max_abs_diff': float(np.max(np.abs(moment_diff))),\n",
    "            'mean_abs_diff': float(np.mean(np.abs(moment_diff))),\n",
    "            'rmse': float(np.sqrt(np.mean(moment_diff**2))),\n",
    "            'max_rel_diff': float(np.max(np.abs(moment_diff / (self.emp_moments + 1e-10)))),\n",
    "            'parameters': parameters.copy()\n",
    "        }\n",
    "        \n",
    "        return sim_moments, diagnostics\n",
    "    \n",
    "    \n",
    "    #Display estimation results\n",
    "    def display_results(self, parameters=None):\n",
    "        if parameters is None:\n",
    "            if not self.estimation_history:\n",
    "                print(\"No estimation results available\")\n",
    "                return None, None\n",
    "            parameters = self.estimation_history[-1]['best_params']\n",
    "        \n",
    "        param_df = pd.DataFrame({\n",
    "            'Parameter': self.param_config['names'],\n",
    "            'Estimate': parameters,\n",
    "            'Lower_Bound': [b[0] for b in self.param_config['bounds']],\n",
    "            'Upper_Bound': [b[1] for b in self.param_config['bounds']]\n",
    "        })\n",
    "        \n",
    "        print(\"\\nEstimated Parameters:\")\n",
    "        print(\"=\"*60)\n",
    "        print(param_df.to_string(index=False, float_format='%.4f'))\n",
    "        \n",
    "        sim_moments, diagnostics = self.evaluate_fit(parameters)\n",
    "        \n",
    "        print(f\"\\nModel Fit Diagnostics:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Objective: {diagnostics['objective_value']:.6f}\")\n",
    "        print(f\"RMSE: {diagnostics['rmse']:.6f}\")\n",
    "        print(f\"Mean Absolute Diff: {diagnostics['mean_abs_diff']:.6f}\")\n",
    "        print(f\"Max Absolute Diff: {diagnostics['max_abs_diff']:.6f}\")\n",
    "        print(f\"Max Relative Diff: {diagnostics['max_rel_diff']:.4f}\")\n",
    "        \n",
    "        return param_df, diagnostics"
   ],
   "id": "138d01e1417cc003",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:13:02.755521Z",
     "start_time": "2025-10-08T16:13:02.723794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  In the paper, the authors use n_individuals=750000 and n_starts=720, which takes more than a week to finish\n",
    "# Here I just use 300000 individuals and 100 starting points to illustrate the results of each run\n",
    "# I run code:\n",
    "#estimator = SMMEstimator(\n",
    "    #emp_moments,\n",
    "    #weighting_matrix=W,\n",
    "    #n_individuals=300000,\n",
    "    ##)\n",
    "#result = estimator.estimate(method='multi_start', n_starts=100)\n",
    "#param_table, diagnostics = estimator.display_results()\n",
    "\n",
    "# Here I show my results of optimal estimation\n",
    "import pickle\n",
    "import pandas as pd\n",
    "with open('smm_checkpoint.pkl', 'rb') as f:\n",
    "    checkpoint = pickle.load(f)\n",
    "print(f\"Process: {checkpoint['completed_starts']}/{checkpoint['total_starts']}\")\n",
    "print(f\"Optimal objective: {checkpoint['best_so_far'].fun:.6f}\\n\")\n",
    "\n",
    "param_names = ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "               'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "               'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "               'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps']\n",
    "df = pd.DataFrame({\n",
    "    'Parameter': param_names,\n",
    "    'Value': checkpoint['best_so_far'].x\n",
    "})\n",
    "print(df.to_string(index=False))"
   ],
   "id": "8c8b2df85646313c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 100/100\n",
      "Optimal objective: 785.368755\n",
      "\n",
      " Parameter      Value\n",
      "      h0_v   0.372406\n",
      "     h0_nv   0.361436\n",
      "       r_v   0.376651\n",
      "      r_nv   0.292714\n",
      "     eta_v   0.145226\n",
      "    eta_nv   0.039576\n",
      "    mu_s_v -22.282835\n",
      "   mu_s_nv -38.815866\n",
      " sigma_s_v  24.442116\n",
      "sigma_s_nv  37.620765\n",
      "   S_svy_v   1.407816\n",
      "  S_svy_nv   5.086271\n",
      " timeval_v  91.398778\n",
      "timeval_nv  81.169499\n",
      "     mu_sv  -6.172388\n",
      "     mu_sn -23.334700\n",
      " sigma_svn  10.758911\n",
      "         L  14.798783\n",
      "    mu_eps -23.684616\n",
      " sigma_eps 145.616936\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:19:50.469338Z",
     "start_time": "2025-10-08T16:19:50.452816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the results\n",
    "with open('smm_checkpoint.pkl', 'rb') as f:\n",
    "    checkpoint = pickle.load(f)\n",
    "\n",
    "your_result = checkpoint['best_so_far']\n",
    "your_params = your_result.x\n",
    "your_objective = your_result.fun\n",
    "print(f\"My Optimal objective: {your_objective:.2f}\")\n",
    "\n",
    "# Comparison\n",
    "# Load the parameters based on authors estimation\n",
    "author_params = np.array([0.38,0.36,0.38,0.30,0.14,0.16,-22.6,-27.7,26.9,24.7,1.6,1.2,42.7,23.9,-3.9,-11.3,9.5,7.6,64.1,318.7]) \n",
    "\n",
    "param_names = ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "               'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "               'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "               'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps']\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Parameter': param_names,\n",
    "    'Your_Estimate': your_params,\n",
    "    'Author_Estimate': author_params,\n",
    "    'Difference': your_params - author_params,\n",
    "    'Pct_Diff': 100 * (your_params - author_params) / np.abs(author_params)\n",
    "})\n",
    "\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))\n"
   ],
   "id": "69c7d0e453366bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Optimal objective: 785.37\n",
      "\n",
      "Parameter Comparison:\n",
      " Parameter  Your_Estimate  Author_Estimate  Difference  Pct_Diff\n",
      "      h0_v         0.3724           0.3800     -0.0076   -1.9985\n",
      "     h0_nv         0.3614           0.3600      0.0014    0.3988\n",
      "       r_v         0.3767           0.3800     -0.0033   -0.8812\n",
      "      r_nv         0.2927           0.3000     -0.0073   -2.4288\n",
      "     eta_v         0.1452           0.1400      0.0052    3.7332\n",
      "    eta_nv         0.0396           0.1600     -0.1204  -75.2651\n",
      "    mu_s_v       -22.2828         -22.6000      0.3172    1.4034\n",
      "   mu_s_nv       -38.8159         -27.7000    -11.1159  -40.1295\n",
      " sigma_s_v        24.4421          26.9000     -2.4579   -9.1371\n",
      "sigma_s_nv        37.6208          24.7000     12.9208   52.3108\n",
      "   S_svy_v         1.4078           1.6000     -0.1922  -12.0115\n",
      "  S_svy_nv         5.0863           1.2000      3.8863  323.8559\n",
      " timeval_v        91.3988          42.7000     48.6988  114.0487\n",
      "timeval_nv        81.1695          23.9000     57.2695  239.6213\n",
      "     mu_sv        -6.1724          -3.9000     -2.2724  -58.2664\n",
      "     mu_sn       -23.3347         -11.3000    -12.0347 -106.5018\n",
      " sigma_svn        10.7589           9.5000      1.2589   13.2517\n",
      "         L        14.7988           7.6000      7.1988   94.7208\n",
      "    mu_eps       -23.6846          64.1000    -87.7846 -136.9495\n",
      " sigma_eps       145.6169         318.7000   -173.0831  -54.3091\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T16:59:19.966802Z",
     "start_time": "2025-10-14T16:59:19.937805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here I try to use different n_individuals and n_starting points, and compare its results with my set up, to see if the estimation is sensitive on the choice of n_individuals and n_starting points \n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    with open('checkpoint_full_720.pkl', 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "    \n",
    "    print(f\"Process: {checkpoint['completed_starts']}/{checkpoint['total_starts']}\")\n",
    "    print(f\"Optimal SSE: {checkpoint['best_so_far'].fun:.2f}\")\n",
    "    print(f\"Authors' SSE:160.3\")\n",
    "    \n",
    "    # Display optimal parameters\n",
    "    best_params = checkpoint['best_so_far'].x\n",
    "    param_names = ['h0_v', 'h0_nv', 'r_v', 'r_nv', 'eta_v', 'eta_nv', \n",
    "                   'mu_s_v', 'mu_s_nv', 'sigma_s_v', 'sigma_s_nv',\n",
    "                   'S_svy_v', 'S_svy_nv', 'timeval_v', 'timeval_nv',\n",
    "                   'mu_sv', 'mu_sn', 'sigma_svn', 'L', 'mu_eps', 'sigma_eps']\n",
    "    \n",
    "    param_df = pd.DataFrame({\n",
    "        'Parameter': param_names,\n",
    "        'Value': best_params\n",
    "    })\n",
    "    \n",
    "    print(\"\\nOptimal Parameters:\")\n",
    "    print(param_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Display the best 5 SSE\n",
    "    all_obj = [r.fun for r in checkpoint['results_list']]\n",
    "    print(f\"\\nFirst 5 best SSE: {sorted(all_obj)[:5]}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "# Comparison\n",
    "# Load the parameters based on authors estimation\n",
    "author_params = np.array([0.38,0.36,0.38,0.30,0.14,0.16,-22.6,-27.7,26.9,24.7,1.6,1.2,42.7,23.9,-3.9,-11.3,9.5,7.6,64.1,318.7]) \n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Parameter': param_names,\n",
    "    'Your_Estimate': best_params,\n",
    "    'Author_Estimate': author_params,\n",
    "    'Difference': best_params - author_params,\n",
    "    'Pct_Diff': 100 * (best_params - author_params) / np.abs(author_params)\n",
    "})\n",
    "\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))"
   ],
   "id": "f14c7ae7fa3da6fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 265/720\n",
      "Optimal SSE: 785.80\n",
      "Authors' SSE:160.3\n",
      "\n",
      "Optimal Parameters:\n",
      " Parameter    Value\n",
      "      h0_v   0.3871\n",
      "     h0_nv   0.3613\n",
      "       r_v   0.3703\n",
      "      r_nv   0.2912\n",
      "     eta_v   0.1119\n",
      "    eta_nv   0.0538\n",
      "    mu_s_v -23.4358\n",
      "   mu_s_nv -40.9584\n",
      " sigma_s_v  23.9570\n",
      "sigma_s_nv  38.9021\n",
      "   S_svy_v   2.1261\n",
      "  S_svy_nv   3.7229\n",
      " timeval_v  46.9499\n",
      "timeval_nv  30.0951\n",
      "     mu_sv  -1.9093\n",
      "     mu_sn -12.2122\n",
      " sigma_svn  11.2064\n",
      "         L  13.7604\n",
      "    mu_eps  -0.7137\n",
      " sigma_eps 192.8456\n",
      "\n",
      "First 5 best SSE: [785.7985628670547, 789.58978505024, 792.4326380990643, 797.6114874240877, 801.0998617341428]\n",
      "\n",
      "Parameter Comparison:\n",
      " Parameter  Your_Estimate  Author_Estimate  Difference  Pct_Diff\n",
      "      h0_v         0.3871           0.3800      0.0071    1.8600\n",
      "     h0_nv         0.3613           0.3600      0.0013    0.3711\n",
      "       r_v         0.3703           0.3800     -0.0097   -2.5421\n",
      "      r_nv         0.2912           0.3000     -0.0088   -2.9494\n",
      "     eta_v         0.1119           0.1400     -0.0281  -20.0606\n",
      "    eta_nv         0.0538           0.1600     -0.1062  -66.3507\n",
      "    mu_s_v       -23.4358         -22.6000     -0.8358   -3.6981\n",
      "   mu_s_nv       -40.9584         -27.7000    -13.2584  -47.8642\n",
      " sigma_s_v        23.9570          26.9000     -2.9430  -10.9407\n",
      "sigma_s_nv        38.9021          24.7000     14.2021   57.4985\n",
      "   S_svy_v         2.1261           1.6000      0.5261   32.8815\n",
      "  S_svy_nv         3.7229           1.2000      2.5229  210.2408\n",
      " timeval_v        46.9499          42.7000      4.2499    9.9529\n",
      "timeval_nv        30.0951          23.9000      6.1951   25.9210\n",
      "     mu_sv        -1.9093          -3.9000      1.9907   51.0440\n",
      "     mu_sn       -12.2122         -11.3000     -0.9122   -8.0722\n",
      " sigma_svn        11.2064           9.5000      1.7064   17.9619\n",
      "         L        13.7604           7.6000      6.1604   81.0580\n",
      "    mu_eps        -0.7137          64.1000    -64.8137 -101.1134\n",
      " sigma_eps       192.8456         318.7000   -125.8544  -39.4899\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comments:\n",
    "(i) The estimation result is relatively stable when I change: n_individuals, n_starting points, as well as when I try different optimization\n",
    "methods.\n",
    "\n",
    "(ii) As I increase the size of n_individuals and n_starting points, the results of my estimation becomes closer to authors'results.\n",
    "\n",
    "(iii) However, the SSE in the paper is significantly lower than mine, which is unlikely to be solely a result of sample size and iteration number. Further investigation is needed.\n"
   ],
   "id": "71f8f46205784e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
